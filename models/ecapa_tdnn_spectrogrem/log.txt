G:\envs\py38\python.exe C:/jupyterNoteBook/VoiceprintRecognition-Pytorch/train.py 
-----------  Configuration Arguments -----------
augment_conf_path: configs/augment.yml
batch_size: 64
feature_method: spectrogram
gpus: 0
learning_rate: 0.001
num_epoch: 30
num_speakers: 3242
num_workers: 8
pretrained_model: None
resume: models/ecapa_tdnn_spectrogrem
save_model_dir: models/
test_list_path: dataset/test_list.txt
train_list_path: dataset/train_list.txt
use_model: ecapa_tdnn
------------------------------------------------
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 512, 98]         514,560
       BatchNorm1d-2              [-1, 512, 98]           1,024
      Conv1dReluBn-3              [-1, 512, 98]               0
            Conv1d-4              [-1, 512, 98]         262,144
       BatchNorm1d-5              [-1, 512, 98]           1,024
      Conv1dReluBn-6              [-1, 512, 98]               0
            Conv1d-7               [-1, 64, 98]          12,288
       BatchNorm1d-8               [-1, 64, 98]             128
            Conv1d-9               [-1, 64, 98]          12,288
      BatchNorm1d-10               [-1, 64, 98]             128
           Conv1d-11               [-1, 64, 98]          12,288
      BatchNorm1d-12               [-1, 64, 98]             128
           Conv1d-13               [-1, 64, 98]          12,288
      BatchNorm1d-14               [-1, 64, 98]             128
           Conv1d-15               [-1, 64, 98]          12,288
      BatchNorm1d-16               [-1, 64, 98]             128
           Conv1d-17               [-1, 64, 98]          12,288
      BatchNorm1d-18               [-1, 64, 98]             128
           Conv1d-19               [-1, 64, 98]          12,288
      BatchNorm1d-20               [-1, 64, 98]             128
 Res2Conv1dReluBn-21              [-1, 512, 98]               0
           Conv1d-22              [-1, 512, 98]         262,144
      BatchNorm1d-23              [-1, 512, 98]           1,024
     Conv1dReluBn-24              [-1, 512, 98]               0
           Linear-25                  [-1, 256]         131,328
           Linear-26                  [-1, 512]         131,584
       SE_Connect-27              [-1, 512, 98]               0
           Conv1d-28              [-1, 512, 98]         262,144
      BatchNorm1d-29              [-1, 512, 98]           1,024
     Conv1dReluBn-30              [-1, 512, 98]               0
           Conv1d-31               [-1, 64, 98]          12,288
      BatchNorm1d-32               [-1, 64, 98]             128
           Conv1d-33               [-1, 64, 98]          12,288
      BatchNorm1d-34               [-1, 64, 98]             128
           Conv1d-35               [-1, 64, 98]          12,288
      BatchNorm1d-36               [-1, 64, 98]             128
           Conv1d-37               [-1, 64, 98]          12,288
      BatchNorm1d-38               [-1, 64, 98]             128
           Conv1d-39               [-1, 64, 98]          12,288
      BatchNorm1d-40               [-1, 64, 98]             128
           Conv1d-41               [-1, 64, 98]          12,288
      BatchNorm1d-42               [-1, 64, 98]             128
           Conv1d-43               [-1, 64, 98]          12,288
      BatchNorm1d-44               [-1, 64, 98]             128
 Res2Conv1dReluBn-45              [-1, 512, 98]               0
           Conv1d-46              [-1, 512, 98]         262,144
      BatchNorm1d-47              [-1, 512, 98]           1,024
     Conv1dReluBn-48              [-1, 512, 98]               0
           Linear-49                  [-1, 256]         131,328
           Linear-50                  [-1, 512]         131,584
       SE_Connect-51              [-1, 512, 98]               0
           Conv1d-52              [-1, 512, 98]         262,144
      BatchNorm1d-53              [-1, 512, 98]           1,024
     Conv1dReluBn-54              [-1, 512, 98]               0
           Conv1d-55               [-1, 64, 98]          12,288
      BatchNorm1d-56               [-1, 64, 98]             128
           Conv1d-57               [-1, 64, 98]          12,288
      BatchNorm1d-58               [-1, 64, 98]             128
           Conv1d-59               [-1, 64, 98]          12,288
      BatchNorm1d-60               [-1, 64, 98]             128
           Conv1d-61               [-1, 64, 98]          12,288
      BatchNorm1d-62               [-1, 64, 98]             128
           Conv1d-63               [-1, 64, 98]          12,288
      BatchNorm1d-64               [-1, 64, 98]             128
           Conv1d-65               [-1, 64, 98]          12,288
      BatchNorm1d-66               [-1, 64, 98]             128
           Conv1d-67               [-1, 64, 98]          12,288
      BatchNorm1d-68               [-1, 64, 98]             128
 Res2Conv1dReluBn-69              [-1, 512, 98]               0
           Conv1d-70              [-1, 512, 98]         262,144
      BatchNorm1d-71              [-1, 512, 98]           1,024
     Conv1dReluBn-72              [-1, 512, 98]               0
           Linear-73                  [-1, 256]         131,328
           Linear-74                  [-1, 512]         131,584
       SE_Connect-75              [-1, 512, 98]               0
           Conv1d-76             [-1, 1536, 98]       2,360,832
           Conv1d-77              [-1, 128, 98]         196,736
           Conv1d-78             [-1, 1536, 98]         198,144
AttentiveStatsPool-79                 [-1, 3072]               0
      BatchNorm1d-80                 [-1, 3072]           6,144
           Linear-81                  [-1, 192]         590,016
      BatchNorm1d-82                  [-1, 192]             384
        EcapaTdnn-83                  [-1, 192]               0
          Dropout-84                  [-1, 192]               0
================================================================
Total params: 6,496,320
Trainable params: 6,496,320
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.08
Forward/backward pass size (MB): 14.81
Params size (MB): 24.78
Estimated Total Size (MB): 39.67
----------------------------------------------------------------
成功加载第 29 轮的模型参数和优化方法参数
[2022-09-26 23:12:42.413304] Train epoch [29/30], batch: [0/16579], loss: 0.53313, accuracy: 0.98438, lr: 0.00014323, eta: 12 days, 17:25:32
[2022-09-26 23:12:53.284139] Train epoch [29/30], batch: [100/16579], loss: 0.43947, accuracy: 0.99196, lr: 0.00014323, eta: 0:35:58
[2022-09-26 23:13:02.750134] Train epoch [29/30], batch: [200/16579], loss: 0.42832, accuracy: 0.99277, lr: 0.00014323, eta: 0:23:28
[2022-09-26 23:13:12.541134] Train epoch [29/30], batch: [300/16579], loss: 0.42707, accuracy: 0.99299, lr: 0.00014323, eta: 0:23:52
[2022-09-26 23:13:21.883134] Train epoch [29/30], batch: [400/16579], loss: 0.42722, accuracy: 0.99310, lr: 0.00014323, eta: 0:22:55
[2022-09-26 23:13:30.354134] Train epoch [29/30], batch: [500/16579], loss: 0.42791, accuracy: 0.99292, lr: 0.00014323, eta: 0:22:14
[2022-09-26 23:13:38.779134] Train epoch [29/30], batch: [600/16579], loss: 0.42814, accuracy: 0.99290, lr: 0.00014323, eta: 0:21:50
[2022-09-26 23:13:47.169137] Train epoch [29/30], batch: [700/16579], loss: 0.42844, accuracy: 0.99267, lr: 0.00014323, eta: 0:21:42
[2022-09-26 23:13:55.562137] Train epoch [29/30], batch: [800/16579], loss: 0.42863, accuracy: 0.99276, lr: 0.00014323, eta: 0:22:05
[2022-09-26 23:14:03.924136] Train epoch [29/30], batch: [900/16579], loss: 0.42628, accuracy: 0.99299, lr: 0.00014323, eta: 0:21:41
[2022-09-26 23:14:12.292135] Train epoch [29/30], batch: [1000/16579], loss: 0.42613, accuracy: 0.99305, lr: 0.00014323, eta: 0:21:17
[2022-09-26 23:14:20.651135] Train epoch [29/30], batch: [1100/16579], loss: 0.42639, accuracy: 0.99303, lr: 0.00014323, eta: 0:21:24
[2022-09-26 23:14:28.987136] Train epoch [29/30], batch: [1200/16579], loss: 0.42856, accuracy: 0.99290, lr: 0.00014323, eta: 0:21:31
[2022-09-26 23:14:37.327135] Train epoch [29/30], batch: [1300/16579], loss: 0.42797, accuracy: 0.99296, lr: 0.00014323, eta: 0:21:08
[2022-09-26 23:14:45.665134] Train epoch [29/30], batch: [1400/16579], loss: 0.42718, accuracy: 0.99305, lr: 0.00014323, eta: 0:20:59
[2022-09-26 23:14:53.963134] Train epoch [29/30], batch: [1500/16579], loss: 0.42677, accuracy: 0.99322, lr: 0.00014323, eta: 0:20:36
[2022-09-26 23:15:02.294134] Train epoch [29/30], batch: [1600/16579], loss: 0.42662, accuracy: 0.99318, lr: 0.00014323, eta: 0:20:43
[2022-09-26 23:15:10.598134] Train epoch [29/30], batch: [1700/16579], loss: 0.42753, accuracy: 0.99307, lr: 0.00014323, eta: 0:20:49
[2022-09-26 23:15:18.893134] Train epoch [29/30], batch: [1800/16579], loss: 0.42754, accuracy: 0.99303, lr: 0.00014323, eta: 0:19:57
[2022-09-26 23:15:27.191139] Train epoch [29/30], batch: [1900/16579], loss: 0.42812, accuracy: 0.99302, lr: 0.00014323, eta: 0:20:18
[2022-09-26 23:15:35.506133] Train epoch [29/30], batch: [2000/16579], loss: 0.42745, accuracy: 0.99313, lr: 0.00014323, eta: 0:20:10
[2022-09-26 23:15:43.809134] Train epoch [29/30], batch: [2100/16579], loss: 0.42773, accuracy: 0.99308, lr: 0.00014323, eta: 0:20:01
[2022-09-26 23:15:52.107137] Train epoch [29/30], batch: [2200/16579], loss: 0.42799, accuracy: 0.99296, lr: 0.00014323, eta: 0:19:10
[2022-09-26 23:16:00.718136] Train epoch [29/30], batch: [2300/16579], loss: 0.42822, accuracy: 0.99294, lr: 0.00014323, eta: 0:19:45
[2022-09-26 23:16:09.363140] Train epoch [29/30], batch: [2400/16579], loss: 0.42826, accuracy: 0.99297, lr: 0.00014323, eta: 0:21:16
[2022-09-26 23:16:18.398135] Train epoch [29/30], batch: [2500/16579], loss: 0.42840, accuracy: 0.99295, lr: 0.00014323, eta: 0:20:38
[2022-09-26 23:16:27.511136] Train epoch [29/30], batch: [2600/16579], loss: 0.42836, accuracy: 0.99296, lr: 0.00014323, eta: 0:21:26
[2022-09-26 23:16:36.591135] Train epoch [29/30], batch: [2700/16579], loss: 0.42858, accuracy: 0.99302, lr: 0.00014323, eta: 0:21:03
[2022-09-26 23:16:45.813134] Train epoch [29/30], batch: [2800/16579], loss: 0.42883, accuracy: 0.99300, lr: 0.00014323, eta: 0:20:12
[2022-09-26 23:16:54.760136] Train epoch [29/30], batch: [2900/16579], loss: 0.42852, accuracy: 0.99302, lr: 0.00014323, eta: 0:19:36
[2022-09-26 23:17:03.427134] Train epoch [29/30], batch: [3000/16579], loss: 0.42871, accuracy: 0.99298, lr: 0.00014323, eta: 0:20:08
[2022-09-26 23:17:12.345136] Train epoch [29/30], batch: [3100/16579], loss: 0.42864, accuracy: 0.99299, lr: 0.00014323, eta: 0:20:13
[2022-09-26 23:17:21.199135] Train epoch [29/30], batch: [3200/16579], loss: 0.42833, accuracy: 0.99301, lr: 0.00014323, eta: 0:19:10
[2022-09-26 23:17:30.400135] Train epoch [29/30], batch: [3300/16579], loss: 0.42863, accuracy: 0.99299, lr: 0.00014323, eta: 0:19:15
[2022-09-26 23:17:39.504134] Train epoch [29/30], batch: [3400/16579], loss: 0.42858, accuracy: 0.99297, lr: 0.00014323, eta: 0:21:05
[2022-09-26 23:17:48.547134] Train epoch [29/30], batch: [3500/16579], loss: 0.42901, accuracy: 0.99295, lr: 0.00014323, eta: 0:18:44
[2022-09-26 23:17:57.669135] Train epoch [29/30], batch: [3600/16579], loss: 0.42908, accuracy: 0.99295, lr: 0.00014323, eta: 0:20:20
[2022-09-26 23:18:06.737136] Train epoch [29/30], batch: [3700/16579], loss: 0.42956, accuracy: 0.99292, lr: 0.00014323, eta: 0:18:40
[2022-09-26 23:18:15.741135] Train epoch [29/30], batch: [3800/16579], loss: 0.42987, accuracy: 0.99289, lr: 0.00014323, eta: 0:20:01
[2022-09-26 23:18:24.809135] Train epoch [29/30], batch: [3900/16579], loss: 0.43073, accuracy: 0.99285, lr: 0.00014323, eta: 0:20:17
[2022-09-26 23:18:33.925135] Train epoch [29/30], batch: [4000/16579], loss: 0.43096, accuracy: 0.99281, lr: 0.00014323, eta: 0:19:29
[2022-09-26 23:18:42.964133] Train epoch [29/30], batch: [4100/16579], loss: 0.43119, accuracy: 0.99283, lr: 0.00014323, eta: 0:19:20
[2022-09-26 23:18:51.930134] Train epoch [29/30], batch: [4200/16579], loss: 0.43158, accuracy: 0.99278, lr: 0.00014323, eta: 0:17:32
[2022-09-26 23:19:01.060135] Train epoch [29/30], batch: [4300/16579], loss: 0.43234, accuracy: 0.99272, lr: 0.00014323, eta: 0:19:26
[2022-09-26 23:19:10.197134] Train epoch [29/30], batch: [4400/16579], loss: 0.43205, accuracy: 0.99272, lr: 0.00014323, eta: 0:17:39
[2022-09-26 23:19:19.316135] Train epoch [29/30], batch: [4500/16579], loss: 0.43177, accuracy: 0.99274, lr: 0.00014323, eta: 0:17:30
[2022-09-26 23:19:28.460135] Train epoch [29/30], batch: [4600/16579], loss: 0.43200, accuracy: 0.99276, lr: 0.00014323, eta: 0:18:46
[2022-09-26 23:19:37.687136] Train epoch [29/30], batch: [4700/16579], loss: 0.43202, accuracy: 0.99278, lr: 0.00014323, eta: 0:18:00
[2022-09-26 23:19:46.843135] Train epoch [29/30], batch: [4800/16579], loss: 0.43219, accuracy: 0.99278, lr: 0.00014323, eta: 0:18:15
[2022-09-26 23:19:55.942135] Train epoch [29/30], batch: [4900/16579], loss: 0.43273, accuracy: 0.99279, lr: 0.00014323, eta: 0:17:54
[2022-09-26 23:20:05.008135] Train epoch [29/30], batch: [5000/16579], loss: 0.43312, accuracy: 0.99277, lr: 0.00014323, eta: 0:17:45
[2022-09-26 23:20:14.034135] Train epoch [29/30], batch: [5100/16579], loss: 0.43332, accuracy: 0.99277, lr: 0.00014323, eta: 0:16:38
[2022-09-26 23:20:23.116134] Train epoch [29/30], batch: [5200/16579], loss: 0.43319, accuracy: 0.99279, lr: 0.00014323, eta: 0:17:26
[2022-09-26 23:20:32.301138] Train epoch [29/30], batch: [5300/16579], loss: 0.43308, accuracy: 0.99280, lr: 0.00014323, eta: 0:17:51
[2022-09-26 23:20:41.872647] Train epoch [29/30], batch: [5400/16579], loss: 0.43347, accuracy: 0.99278, lr: 0.00014323, eta: 0:17:53
[2022-09-26 23:20:51.013647] Train epoch [29/30], batch: [5500/16579], loss: 0.43358, accuracy: 0.99279, lr: 0.00014323, eta: 0:16:37
[2022-09-26 23:21:00.443649] Train epoch [29/30], batch: [5600/16579], loss: 0.43369, accuracy: 0.99282, lr: 0.00014323, eta: 0:18:39
[2022-09-26 23:21:09.562650] Train epoch [29/30], batch: [5700/16579], loss: 0.43442, accuracy: 0.99280, lr: 0.00014323, eta: 0:16:08
[2022-09-26 23:21:19.081651] Train epoch [29/30], batch: [5800/16579], loss: 0.43437, accuracy: 0.99278, lr: 0.00014323, eta: 0:16:31
[2022-09-26 23:21:28.508647] Train epoch [29/30], batch: [5900/16579], loss: 0.43467, accuracy: 0.99277, lr: 0.00014323, eta: 0:17:15
[2022-09-26 23:21:37.975648] Train epoch [29/30], batch: [6000/16579], loss: 0.43450, accuracy: 0.99278, lr: 0.00014323, eta: 0:17:06
[2022-09-26 23:21:47.345650] Train epoch [29/30], batch: [6100/16579], loss: 0.43445, accuracy: 0.99279, lr: 0.00014323, eta: 0:16:46
[2022-09-26 23:21:56.662651] Train epoch [29/30], batch: [6200/16579], loss: 0.43441, accuracy: 0.99276, lr: 0.00014323, eta: 0:15:02
[2022-09-26 23:22:06.097649] Train epoch [29/30], batch: [6300/16579], loss: 0.43469, accuracy: 0.99276, lr: 0.00014323, eta: 0:16:06
[2022-09-26 23:22:15.443648] Train epoch [29/30], batch: [6400/16579], loss: 0.43510, accuracy: 0.99275, lr: 0.00014323, eta: 0:15:56
[2022-09-26 23:22:24.812647] Train epoch [29/30], batch: [6500/16579], loss: 0.43533, accuracy: 0.99274, lr: 0.00014323, eta: 0:16:07
[2022-09-26 23:22:34.256647] Train epoch [29/30], batch: [6600/16579], loss: 0.43563, accuracy: 0.99271, lr: 0.00014323, eta: 0:15:57
[2022-09-26 23:22:43.747647] Train epoch [29/30], batch: [6700/16579], loss: 0.43605, accuracy: 0.99270, lr: 0.00014323, eta: 0:15:58
[2022-09-26 23:22:53.120650] Train epoch [29/30], batch: [6800/16579], loss: 0.43622, accuracy: 0.99269, lr: 0.00014323, eta: 0:15:28
[2022-09-26 23:23:02.517649] Train epoch [29/30], batch: [6900/16579], loss: 0.43641, accuracy: 0.99268, lr: 0.00014323, eta: 0:14:11
[2022-09-26 23:23:11.933647] Train epoch [29/30], batch: [7000/16579], loss: 0.43655, accuracy: 0.99269, lr: 0.00014323, eta: 0:13:53
[2022-09-26 23:23:21.323650] Train epoch [29/30], batch: [7100/16579], loss: 0.43672, accuracy: 0.99270, lr: 0.00014323, eta: 0:15:00
[2022-09-26 23:23:30.673650] Train epoch [29/30], batch: [7200/16579], loss: 0.43682, accuracy: 0.99269, lr: 0.00014323, eta: 0:14:04
[2022-09-26 23:23:40.135649] Train epoch [29/30], batch: [7300/16579], loss: 0.43693, accuracy: 0.99268, lr: 0.00014323, eta: 0:15:18
[2022-09-26 23:23:49.556654] Train epoch [29/30], batch: [7400/16579], loss: 0.43691, accuracy: 0.99268, lr: 0.00014323, eta: 0:13:36
[2022-09-26 23:23:58.989651] Train epoch [29/30], batch: [7500/16579], loss: 0.43683, accuracy: 0.99268, lr: 0.00014323, eta: 0:14:13
[2022-09-26 23:24:08.362650] Train epoch [29/30], batch: [7600/16579], loss: 0.43711, accuracy: 0.99268, lr: 0.00014323, eta: 0:13:19
[2022-09-26 23:24:17.782647] Train epoch [29/30], batch: [7700/16579], loss: 0.43725, accuracy: 0.99270, lr: 0.00014323, eta: 0:13:54
[2022-09-26 23:24:27.155649] Train epoch [29/30], batch: [7800/16579], loss: 0.43743, accuracy: 0.99270, lr: 0.00014323, eta: 0:13:53
[2022-09-26 23:24:36.516649] Train epoch [29/30], batch: [7900/16579], loss: 0.43765, accuracy: 0.99270, lr: 0.00014323, eta: 0:12:43
[2022-09-26 23:24:45.933647] Train epoch [29/30], batch: [8000/16579], loss: 0.43782, accuracy: 0.99270, lr: 0.00014323, eta: 0:13:00
[2022-09-26 23:24:55.226650] Train epoch [29/30], batch: [8100/16579], loss: 0.43787, accuracy: 0.99270, lr: 0.00014323, eta: 0:12:09
[2022-09-26 23:25:04.231647] Train epoch [29/30], batch: [8200/16579], loss: 0.43810, accuracy: 0.99269, lr: 0.00014323, eta: 0:12:42
[2022-09-26 23:25:13.280650] Train epoch [29/30], batch: [8300/16579], loss: 0.43825, accuracy: 0.99269, lr: 0.00014323, eta: 0:11:43
[2022-09-26 23:25:22.360651] Train epoch [29/30], batch: [8400/16579], loss: 0.43845, accuracy: 0.99269, lr: 0.00014323, eta: 0:12:40
[2022-09-26 23:25:31.384649] Train epoch [29/30], batch: [8500/16579], loss: 0.43861, accuracy: 0.99269, lr: 0.00014323, eta: 0:12:15
[2022-09-26 23:25:40.394649] Train epoch [29/30], batch: [8600/16579], loss: 0.43866, accuracy: 0.99269, lr: 0.00014323, eta: 0:11:18
[2022-09-26 23:25:49.393648] Train epoch [29/30], batch: [8700/16579], loss: 0.43897, accuracy: 0.99268, lr: 0.00014323, eta: 0:11:09
[2022-09-26 23:25:58.396647] Train epoch [29/30], batch: [8800/16579], loss: 0.43922, accuracy: 0.99268, lr: 0.00014323, eta: 0:11:55
[2022-09-26 23:26:07.700647] Train epoch [29/30], batch: [8900/16579], loss: 0.43937, accuracy: 0.99266, lr: 0.00014323, eta: 0:12:24
[2022-09-26 23:26:17.041652] Train epoch [29/30], batch: [9000/16579], loss: 0.43957, accuracy: 0.99266, lr: 0.00014323, eta: 0:12:07
[2022-09-26 23:26:26.375647] Train epoch [29/30], batch: [9100/16579], loss: 0.43980, accuracy: 0.99265, lr: 0.00014323, eta: 0:11:50
[2022-09-26 23:26:35.782649] Train epoch [29/30], batch: [9200/16579], loss: 0.43999, accuracy: 0.99265, lr: 0.00014323, eta: 0:11:11
[2022-09-26 23:26:45.143649] Train epoch [29/30], batch: [9300/16579], loss: 0.44029, accuracy: 0.99264, lr: 0.00014323, eta: 0:11:24
[2022-09-26 23:26:54.449650] Train epoch [29/30], batch: [9400/16579], loss: 0.44059, accuracy: 0.99264, lr: 0.00014323, eta: 0:11:29
[2022-09-26 23:27:03.893649] Train epoch [29/30], batch: [9500/16579], loss: 0.44073, accuracy: 0.99264, lr: 0.00014323, eta: 0:11:12
[2022-09-26 23:27:13.301649] Train epoch [29/30], batch: [9600/16579], loss: 0.44063, accuracy: 0.99265, lr: 0.00014323, eta: 0:11:02
[2022-09-26 23:27:22.761650] Train epoch [29/30], batch: [9700/16579], loss: 0.44097, accuracy: 0.99262, lr: 0.00014323, eta: 0:10:05
[2022-09-26 23:27:32.117651] Train epoch [29/30], batch: [9800/16579], loss: 0.44115, accuracy: 0.99261, lr: 0.00014323, eta: 0:11:04
[2022-09-26 23:27:41.518650] Train epoch [29/30], batch: [9900/16579], loss: 0.44141, accuracy: 0.99260, lr: 0.00014323, eta: 0:10:47
[2022-09-26 23:27:50.907650] Train epoch [29/30], batch: [10000/16579], loss: 0.44140, accuracy: 0.99260, lr: 0.00014323, eta: 0:09:58
[2022-09-26 23:28:00.215648] Train epoch [29/30], batch: [10100/16579], loss: 0.44166, accuracy: 0.99258, lr: 0.00014323, eta: 0:10:02
[2022-09-26 23:28:09.640649] Train epoch [29/30], batch: [10200/16579], loss: 0.44188, accuracy: 0.99258, lr: 0.00014323, eta: 0:09:34
[2022-09-26 23:28:18.897650] Train epoch [29/30], batch: [10300/16579], loss: 0.44186, accuracy: 0.99258, lr: 0.00014323, eta: 0:09:25
[2022-09-26 23:28:28.292647] Train epoch [29/30], batch: [10400/16579], loss: 0.44209, accuracy: 0.99257, lr: 0.00014323, eta: 0:09:16
[2022-09-26 23:28:37.657647] Train epoch [29/30], batch: [10500/16579], loss: 0.44218, accuracy: 0.99257, lr: 0.00014323, eta: 0:09:37
[2022-09-26 23:28:47.017648] Train epoch [29/30], batch: [10600/16579], loss: 0.44238, accuracy: 0.99257, lr: 0.00014323, eta: 0:09:22
[2022-09-26 23:28:56.408647] Train epoch [29/30], batch: [10700/16579], loss: 0.44260, accuracy: 0.99256, lr: 0.00014323, eta: 0:08:31
[2022-09-26 23:29:05.742649] Train epoch [29/30], batch: [10800/16579], loss: 0.44252, accuracy: 0.99256, lr: 0.00014323, eta: 0:08:45
[2022-09-26 23:29:14.642648] Train epoch [29/30], batch: [10900/16579], loss: 0.44268, accuracy: 0.99256, lr: 0.00014323, eta: 0:08:25
[2022-09-26 23:29:23.627651] Train epoch [29/30], batch: [11000/16579], loss: 0.44290, accuracy: 0.99254, lr: 0.00014323, eta: 0:08:33
[2022-09-26 23:29:32.687650] Train epoch [29/30], batch: [11100/16579], loss: 0.44301, accuracy: 0.99255, lr: 0.00014323, eta: 0:08:24
[2022-09-26 23:29:41.656647] Train epoch [29/30], batch: [11200/16579], loss: 0.44312, accuracy: 0.99256, lr: 0.00014323, eta: 0:08:04
[2022-09-26 23:29:50.711649] Train epoch [29/30], batch: [11300/16579], loss: 0.44314, accuracy: 0.99254, lr: 0.00014323, eta: 0:07:28
[2022-09-26 23:29:59.757649] Train epoch [29/30], batch: [11400/16579], loss: 0.44327, accuracy: 0.99253, lr: 0.00014323, eta: 0:07:35
[2022-09-26 23:30:08.726649] Train epoch [29/30], batch: [11500/16579], loss: 0.44355, accuracy: 0.99252, lr: 0.00014323, eta: 0:07:42
[2022-09-26 23:30:17.745648] Train epoch [29/30], batch: [11600/16579], loss: 0.44379, accuracy: 0.99250, lr: 0.00014323, eta: 0:07:03
[2022-09-26 23:30:26.703649] Train epoch [29/30], batch: [11700/16579], loss: 0.44387, accuracy: 0.99250, lr: 0.00014323, eta: 0:07:23
[2022-09-26 23:30:35.715650] Train epoch [29/30], batch: [11800/16579], loss: 0.44406, accuracy: 0.99249, lr: 0.00014323, eta: 0:07:19
[2022-09-26 23:30:44.666650] Train epoch [29/30], batch: [11900/16579], loss: 0.44433, accuracy: 0.99248, lr: 0.00014323, eta: 0:07:19
[2022-09-26 23:30:53.685648] Train epoch [29/30], batch: [12000/16579], loss: 0.44456, accuracy: 0.99248, lr: 0.00014323, eta: 0:07:10
[2022-09-26 23:31:02.674649] Train epoch [29/30], batch: [12100/16579], loss: 0.44457, accuracy: 0.99248, lr: 0.00014323, eta: 0:06:56
[2022-09-26 23:31:11.746649] Train epoch [29/30], batch: [12200/16579], loss: 0.44475, accuracy: 0.99248, lr: 0.00014323, eta: 0:06:34
[2022-09-26 23:31:20.726650] Train epoch [29/30], batch: [12300/16579], loss: 0.44499, accuracy: 0.99248, lr: 0.00014323, eta: 0:06:29
[2022-09-26 23:31:29.732649] Train epoch [29/30], batch: [12400/16579], loss: 0.44511, accuracy: 0.99249, lr: 0.00014323, eta: 0:06:32
[2022-09-26 23:31:38.795648] Train epoch [29/30], batch: [12500/16579], loss: 0.44514, accuracy: 0.99249, lr: 0.00014323, eta: 0:06:19
[2022-09-26 23:31:47.771649] Train epoch [29/30], batch: [12600/16579], loss: 0.44549, accuracy: 0.99246, lr: 0.00014323, eta: 0:05:38
[2022-09-26 23:31:56.801647] Train epoch [29/30], batch: [12700/16579], loss: 0.44588, accuracy: 0.99243, lr: 0.00014323, eta: 0:05:33
[2022-09-26 23:32:05.798651] Train epoch [29/30], batch: [12800/16579], loss: 0.44628, accuracy: 0.99242, lr: 0.00014323, eta: 0:05:21
[2022-09-26 23:32:14.840649] Train epoch [29/30], batch: [12900/16579], loss: 0.44629, accuracy: 0.99242, lr: 0.00014323, eta: 0:05:45
[2022-09-26 23:32:23.840651] Train epoch [29/30], batch: [13000/16579], loss: 0.44641, accuracy: 0.99242, lr: 0.00014323, eta: 0:05:22
[2022-09-26 23:32:32.743648] Train epoch [29/30], batch: [13100/16579], loss: 0.44656, accuracy: 0.99241, lr: 0.00014323, eta: 0:05:20
[2022-09-26 23:32:41.803650] Train epoch [29/30], batch: [13200/16579], loss: 0.44678, accuracy: 0.99241, lr: 0.00014323, eta: 0:05:10
[2022-09-26 23:32:50.842648] Train epoch [29/30], batch: [13300/16579], loss: 0.44698, accuracy: 0.99240, lr: 0.00014323, eta: 0:04:51
[2022-09-26 23:32:59.897648] Train epoch [29/30], batch: [13400/16579], loss: 0.44718, accuracy: 0.99239, lr: 0.00014323, eta: 0:04:58
[2022-09-26 23:33:08.853647] Train epoch [29/30], batch: [13500/16579], loss: 0.44723, accuracy: 0.99239, lr: 0.00014323, eta: 0:04:18
[2022-09-26 23:33:17.751647] Train epoch [29/30], batch: [13600/16579], loss: 0.44742, accuracy: 0.99239, lr: 0.00014323, eta: 0:04:40
[2022-09-26 23:33:26.768650] Train epoch [29/30], batch: [13700/16579], loss: 0.44760, accuracy: 0.99238, lr: 0.00014323, eta: 0:04:07
[2022-09-26 23:33:35.826650] Train epoch [29/30], batch: [13800/16579], loss: 0.44775, accuracy: 0.99236, lr: 0.00014323, eta: 0:04:15
[2022-09-26 23:33:44.823651] Train epoch [29/30], batch: [13900/16579], loss: 0.44779, accuracy: 0.99235, lr: 0.00014323, eta: 0:03:55
[2022-09-26 23:33:53.864647] Train epoch [29/30], batch: [14000/16579], loss: 0.44789, accuracy: 0.99234, lr: 0.00014323, eta: 0:03:36
[2022-09-26 23:34:02.820649] Train epoch [29/30], batch: [14100/16579], loss: 0.44787, accuracy: 0.99234, lr: 0.00014323, eta: 0:03:48
[2022-09-26 23:34:11.888649] Train epoch [29/30], batch: [14200/16579], loss: 0.44792, accuracy: 0.99234, lr: 0.00014323, eta: 0:03:29
[2022-09-26 23:34:20.790647] Train epoch [29/30], batch: [14300/16579], loss: 0.44803, accuracy: 0.99234, lr: 0.00014323, eta: 0:03:15
[2022-09-26 23:34:29.710650] Train epoch [29/30], batch: [14400/16579], loss: 0.44814, accuracy: 0.99234, lr: 0.00014323, eta: 0:03:24
[2022-09-26 23:34:38.780651] Train epoch [29/30], batch: [14500/16579], loss: 0.44818, accuracy: 0.99234, lr: 0.00014323, eta: 0:03:11
[2022-09-26 23:34:47.770649] Train epoch [29/30], batch: [14600/16579], loss: 0.44841, accuracy: 0.99232, lr: 0.00014323, eta: 0:03:02
[2022-09-26 23:34:56.739647] Train epoch [29/30], batch: [14700/16579], loss: 0.44864, accuracy: 0.99232, lr: 0.00014323, eta: 0:02:52
[2022-09-26 23:35:05.642649] Train epoch [29/30], batch: [14800/16579], loss: 0.44875, accuracy: 0.99231, lr: 0.00014323, eta: 0:02:32
[2022-09-26 23:35:14.629649] Train epoch [29/30], batch: [14900/16579], loss: 0.44884, accuracy: 0.99230, lr: 0.00014323, eta: 0:02:36
[2022-09-26 23:35:23.704649] Train epoch [29/30], batch: [15000/16579], loss: 0.44902, accuracy: 0.99229, lr: 0.00014323, eta: 0:02:25
[2022-09-26 23:35:32.677648] Train epoch [29/30], batch: [15100/16579], loss: 0.44922, accuracy: 0.99229, lr: 0.00014323, eta: 0:02:04
[2022-09-26 23:35:41.716649] Train epoch [29/30], batch: [15200/16579], loss: 0.44923, accuracy: 0.99230, lr: 0.00014323, eta: 0:02:04
[2022-09-26 23:35:50.780648] Train epoch [29/30], batch: [15300/16579], loss: 0.44939, accuracy: 0.99230, lr: 0.00014323, eta: 0:01:57
[2022-09-26 23:35:59.782647] Train epoch [29/30], batch: [15400/16579], loss: 0.44960, accuracy: 0.99229, lr: 0.00014323, eta: 0:01:52
[2022-09-26 23:36:08.763648] Train epoch [29/30], batch: [15500/16579], loss: 0.44985, accuracy: 0.99227, lr: 0.00014323, eta: 0:01:39
[2022-09-26 23:36:17.824650] Train epoch [29/30], batch: [15600/16579], loss: 0.44999, accuracy: 0.99227, lr: 0.00014323, eta: 0:01:29
[2022-09-26 23:36:26.848651] Train epoch [29/30], batch: [15700/16579], loss: 0.44999, accuracy: 0.99226, lr: 0.00014323, eta: 0:01:16
[2022-09-26 23:36:35.862649] Train epoch [29/30], batch: [15800/16579], loss: 0.45011, accuracy: 0.99226, lr: 0.00014323, eta: 0:01:10
[2022-09-26 23:36:44.887650] Train epoch [29/30], batch: [15900/16579], loss: 0.45015, accuracy: 0.99225, lr: 0.00014323, eta: 0:01:04
[2022-09-26 23:36:53.803647] Train epoch [29/30], batch: [16000/16579], loss: 0.45038, accuracy: 0.99225, lr: 0.00014323, eta: 0:00:49
[2022-09-26 23:37:02.825647] Train epoch [29/30], batch: [16100/16579], loss: 0.45037, accuracy: 0.99226, lr: 0.00014323, eta: 0:00:42
[2022-09-26 23:37:11.856650] Train epoch [29/30], batch: [16200/16579], loss: 0.45041, accuracy: 0.99225, lr: 0.00014323, eta: 0:00:32
[2022-09-26 23:37:20.796648] Train epoch [29/30], batch: [16300/16579], loss: 0.45037, accuracy: 0.99225, lr: 0.00014323, eta: 0:00:25
[2022-09-26 23:37:29.828651] Train epoch [29/30], batch: [16400/16579], loss: 0.45048, accuracy: 0.99224, lr: 0.00014323, eta: 0:00:16
[2022-09-26 23:37:38.887650] Train epoch [29/30], batch: [16500/16579], loss: 0.45066, accuracy: 0.99223, lr: 0.00014323, eta: 0:00:07
======================================================================
[2022-09-26 23:39:22.034413] Test 29, accuracy: 0.97578 time: 0:01:33
======================================================================

进程已结束,退出代码0
